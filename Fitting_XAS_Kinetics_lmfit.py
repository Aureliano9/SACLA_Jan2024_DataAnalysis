# -*- coding: utf-8 -*-
"""
Created on Tue Aug 23 16:06:00 2022

@author: nurekeye

Fitting XAS Kinetics data from SACLA
csv files are generated by sorting code
lmfit package is used
"""

#import libraries
import time
start_time = time.time()

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import lmfit as lf
from scipy import special
from scipy.integrate import quad
from collections import defaultdict


#define functions for fitting
def custom_errfunc(x,x0,y0,a,g):
    return y0 + a*(1+ special.erf((x-x0) / (g/np.sqrt(2)) ) )

#exponent multiplied by Heviside function. While x0 in the exponent is unnecessary,
#it is easier to interpret fit results when it's there
def custom_exp_hevi(x,amp_exp,tau,x0):
    return amp_exp*np.exp(-(x-x0)/tau)*np.heaviside(x-x0,0.5)

#Sum of two exponents multiplied by Heviside function.
def custom_double_exp_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0):
    return ( (amp_exp1*np.exp(-(x)/tau1)) + (amp_exp2*np.exp(-(x)/tau2)) ) * np.heaviside(x-x0,1)

#Gaussian. Coefficient 2.3548200450309493 makues sure that width is equal to FWHM of a Gaussian,
#hence, to an FWHM of a derivative of a rise-time of a fitted function custom_conv()
def custom_gauss(x,amp_gauss,width):
    return amp_gauss * ( 1/( (width/2.3548200450309493)*np.sqrt(2*np.pi)) ) * np.exp( -((x)**2) / (2*((width/2.3548200450309493)**2) ) )

# =============================================================================
# def custom_gauss(x,amp_gauss,width,xc):
#     return amp_gauss * ( 1/( (width/2.3548200450309493)*np.sqrt(2*np.pi)) ) * np.exp( -((x-xc)**2) / (2*((width/2.3548200450309493)**2) ) )
# =============================================================================

#Convolution of functions custom_exp_hevi() and custom_gauss(). Convolution is not evaluated over the whole time range.
#Expected rise time is about 300 fs, 
#so a Gaussian of such a width is almost fully defind within 10*width, i.e. within 3000 fs 
#(that's what k-1500,k+1500 refers to, k is the center of a Gaussion).
#Evaluating the convolution over the whole time range doesn't improve the result.
#Also,since bin size in data is 25 fs, the grid is 5 fs, that's where 601 comes from.

def custom_conv(x,x0,y0,amp_gauss,width,amp_exp,tau):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1500, xk+1500, 601) #set the grid over which to integrate
        f1 = custom_exp_hevi(grid_x,amp_exp,tau,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Convolution of functions custom_double_exp_hevi() and custom_gauss()
def custom_conv2(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
    res_f = [] #final convoluted function 
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1500, xk+1500, 601) #set the grid over which to integrate
        f1 = custom_double_exp_hevi(grid_x,amp_exp1,tau1,amp_exp2,tau2,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

# =============================================================================
# def dd(x,x0,y0,amp_gauss,width,xc,amp_exp1,tau1,amp_exp2,tau2):
#     return custom_double_exp_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0)*custom_gauss(x,amp_gauss,width,xc)
# 
# def custom_conv2(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
#     res_f = [] #final convoluted function 
#     for xk in x: #
#         integral, err = quad(dd, xk-1500, xk+1500, args=(x0,y0,amp_gauss,width,xk,amp_exp1,tau1,amp_exp2,tau2)) #evaluating the integral
#         res_f.extend([integral]) 
#     return ( y0 + np.array(res_f) )
# =============================================================================

def cc(r0, x, rxn, D, sigma):
    Omega0 = 1 - ( rxn * special.erfc( (r0 - rxn) / np.sqrt(4*D*x) ) / r0)
    f = 0.14* Omega0 * np.exp(- r0**2 / (2*sigma**2)) * 4 * np.pi * r0**2 / np.sqrt(8 * np.pi**3 * sigma**6)
    return f

def diffusion(x, r0, rxn, D, sigma):
    Omega = []
    for i in x:
        Omega.append(quad(func=cc, a=rxn, b=np.inf, args=(i, rxn, D, sigma))[0])
    return Omega
    
#Data directory and directory where to save the results
Directory ='C:/Users/nurekeye/Desktop/Projects/SACLA_05-2022/DataAnalysis/2023_06_21/'
Save_Directory = 'C:/Users/nurekeye/Desktop/Projects/SACLA_05-2022/DataAnalysis/Fit_results/2023_07_12/'


EnergyXray = 'Lorentzian'
# EnergyXray = 'Edge'
# EnergyXray = '1st-min'
# EnergyXray = 'Abs-max'

EnergyLaser = '_5uJ'
# EnergyLaser = '_2.9uJ'

PolarisationLaser = '_hor'
# PolarisationLaser = '_ver'


#All the runs, comment/uncomment as needed. Don't uncomment Runs0 and Runs1 simultaneously
# Runs0 = np.array([1145374,1145375,1145376,1145388,1145436,1145437]) #Lorentzian, 5 uJ, hor
# Runs1 = np.array([1145374,1145375,1145376,1145380,1145389,1145409,1145436,1145437]) #Lorentzian, 2.9 uJ, hor

# Runs0 = np.array([1145411,1145442,1145443]) #Lorentzian, 5 uJ, ver
# Runs1 = np.array([1145410,1145442,1145443]) #Lorentzian, 2.9 uJ, ver

# Runs0 = np.array([1145381,1145382,1145383,1145384,1145385,1145387,1145438,1145446]) #Edge, 5 uJ, hor
# Runs1 = np.array([1145381,1145382,1145383,1145384,1145385,1145387,1145438,1145446]) #Edge, 2.9 uJ, hor

# Runs0 = np.array([1145444,1145445]) #Edge, 5 uJ, ver
# Runs1 = np.array([1145444,1145445]) #Edge, 2.9 uJ, ver

# Runs0 = np.array([1145439]) #1st min, 5 uJ, hor
# Runs1 = np.array([1145439]) #1st min, 2.9 uJ, hor

# Runs0 = np.array([1145440,1145441]) #1st min, 5 uJ, ver
# Runs1 = np.array([1145440,1145441]) #1st min, 2.9 uJ, ver

# Runs0 = np.array([1145377,1145378]) #abs max, 5 uJ, hor
# Runs1 = np.array([1145377,1145378,1145379]) #abs max, 2.9 uJ, hor

Runs0 = np.array([1145437]) #test runs

# Create empty dictionaries to fill them with Pandas DataFrames, each key corresponds to a run
data = {} #timing tool corrected
datau = {} #uncorrected

#load the data. Error appears if you have either Runs0 or Runs1 uncommented, but not both of them. That's intednded, ignore
if 'Runs0' in locals():
    Runs = Runs0
    for i in Runs0:
        # i=1145436
        data[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_0.csv', delimiter=',').replace(' ',np.nan).astype(float)
        # datau[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_0_uncorrected.csv', delimiter=',').replace(' ',np.nan).astype(float)
if 'Runs1' in locals():
    Runs = Runs1
    for i in Runs1:
        # i=1145436
        data[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_-2500.csv', delimiter=',').replace(' ',np.nan).astype(float)
        # datau[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_-2500_uncorrected.csv', delimiter=',').replace(' ',np.nan).astype(float)

#Set the model with lmfit
#Create empty dictionaries to fill with fit results
fit_res = {}
fit_report = {}
fit_range_u=500 #Upper limit of fitting range in fs, lower limit hasn't been used so far

#Fitting itself. Standard deviation is used as weights.
#Common Levenbergâ€“Marquardt algorithm didn't work well, and among 20 different algorithms
#"differential evolution" method was the one with the best results, also it didn't take forever
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # y_axis = np.array(data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)])
    y_axis = np.array(data[str(k)].TFY_on[(data[str(k)].Delays_on>fit_range_u)] - baseline)
    x_axis = np.array(data[str(k)].Delays_on[(data[str(k)].Delays_on>fit_range_u)] -500)
    stddev = np.array(data[str(k)].TFY_on_std[(data[str(k)].Delays_on>fit_range_u)])
    
    mid_value = np.mean( y_axis[(300<x_axis) & (x_axis<700)] )/2
    list_a = y_axis[x_axis<500]
    mid_value_real = list_a[min(range(len(list_a)), key=lambda i: abs(list_a[i]-mid_value))]
    t0 = x_axis[y_axis == mid_value_real]
    t0 = float(t0)
    amp_exp0 = float(abs(mid_value*2))
    
# =============================================================================
#     gmodel = lf.Model(custom_conv)
#     params = lf.create_params( x0=dict(value=t0, vary=True, min=-200, max=500), #Time zero in fs
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=300, vary=True, min=100, max=500), #Gaussian width
#                           amp_exp=dict(value=amp_exp0, vary=True, min=0.01, max=0.2), #Exponent amplitude in a.u.
#                           tau=dict(value=19486, vary=True, min=10000, max=90000) ) #Exponent lifetime in fs
# =============================================================================
    
# =============================================================================
#     gmodel = lf.Model(custom_conv2)
#     params = lf.create_params( x0=dict(value=t0+20, vary=True, min=-200, max=500), #Time zero in fs
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=300, vary=True, min=100, max=500), #Gaussian width
#                           amp_exp1=dict(value=amp_exp0/2, vary=True, min=0.01, max=0.2), #Exponent amplitude in a.u.
#                           tau1=dict(value=19486, vary=True, min=10000, max=50000), #Exponent lifetime in fs
#                           amp_exp2=dict(value=amp_exp0/2, vary=True, min=0.01, max=0.2), #Exponent amplitude in a.u.
#                           tau2=dict(value=200000, vary=True, min=10000) ) #Exponent lifetime in fs
# =============================================================================
    
# =============================================================================
#     gmodel = lf.Model(custom_errfunc)
#     params = lf.create_params( x0=dict(value=100, vary=True, min=-200, max=500), #Time zero in fs
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           a=dict(value=0.0386, vary=True, min=0.01, max=0.2), #Error function amplitude in a.u.
#                           g=dict(value=237, vary=True, min=100, max=500)) #Error function width in ps
# =============================================================================
     
    gmodel = lf.Model(diffusion)
    params = lf.create_params( r0=dict(value=10, vary=True, min=4), 
                              rxn=dict(value=4, vary=False, min=0), 
                              D=dict(value=10, vary=True, min=0), 
                              sigma=dict(value=20, vary=True, min=0) ) 
        
    result = gmodel.fit(y_axis, params=params, x=x_axis, 
                        weights = 1/stddev,
                        method = 'nelder')
    fit_res[str(k)] = result #save fit results in internal lmfit format
    fit_report[str(k)] = result.fit_report() #save fit report
    # lf.model.save_modelresult(fit_res[str(k)], Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/'+str(k) + EnergyLaser + '.sav') #saving fit results in internal lmfit format in .sav file for 2.9 uJ

    #Plotting the fit results.    
# =============================================================================
#     plt.figure(str(k),figsize=[16,8], dpi=200)
#     plt.plot(x_axis, y_axis, '.', label='data')
#     plt.plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
#     plt.plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
#     plt.legend(loc='upper right')
#     plt.xlim([min(x_axis)-max(x_axis), max(x_axis)])
#     plt.ylabel('Intensity (a.u.)')
#     plt.xlabel('Delay (fs)')
#     plt.text(min(x_axis)-max(x_axis), min(y_axis), s=result.fit_report(), fontsize=7)
# =============================================================================
    
    figs, axes = plt.subplots(2,1, sharex=True, height_ratios=[5,1], num=k, figsize=[16,8], dpi=200)
    figs.subplots_adjust(hspace=0)
    axes[0].plot(x_axis, y_axis, '.', label='data')
    axes[0].plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
    axes[0].plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
    axes[0].legend(loc='upper right')
    axes[0].set_ylabel('Intensity (a.u.)')
    axes[0].text(min(x_axis)-max(x_axis), min(y_axis), s=fit_res[str(k)].fit_report(), fontsize=7)
    axes[1].plot(x_axis, fit_res[str(k)].residual)
    # axes[1].set_ylabel('Resid')
    axes[1].set_xlim([min(x_axis)-max(x_axis), max(x_axis)])
    axes[1].set_xlabel('Delay (fs)')
    
    mng = plt.get_current_fig_manager()
    mng.window.showMaximized()
    # plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/'+str(k)+ EnergyLaser + '.png',dpi=300) #saving figures in .png file for 2.9 uJ
    print(fit_res[str(k)].values)

    fig, axes = plt.subplots(1,1, num=k*2, dpi=200)
    comps = fit_res[str(k)].eval_components(x=x_axis)
    dely = fit_res[str(k)].eval_uncertainty(sigma=3)
    axes.plot(x_axis, y_axis, '.', markersize=3, label='data')
    axes.plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
    axes.fill_between(x_axis, fit_res[str(k)].best_fit-dely, fit_res[str(k)].best_fit+dely,
                            color="#C5C9C7", label=r'3-$\sigma$ band')
    axes.set_title('data, best-fit, and uncertainty band')
    axes.legend()

#%% Now attempting to normalized the data by correcting for the amplitude of the exponent and time-zero     
'''
New_Delays = {}
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # amplitude = fit_res[str(k)].values['amp_exp']
    amplitude = fit_res[str(k)].values['amp_exp1'] + fit_res[str(k)].values['amp_exp2']

    plt.figure(10) #plot the data corrected for exponent amplitude only
    plt.plot( data[str(k)].Delays_on, (data[str(k)].TFY_on - baseline) / amplitude)
    plt.xlim([-600,5000])
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (fs)')
    
    plt.figure(11) #plot the fitted functions, uncorrected
    plt.plot(data[str(k)].Delays_on[(data[str(k)].Delays_on<fit_range_u)], fit_res[str(k)].best_fit, '-', label='best fit')
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (fs)')
    
    #Shift the time-zeros for the data so that x0 = 0.
    #Since binning is 25 fs, the shifts are made to be the integers of 25 fs,
    #Of course, the remainders are taken into account as well.
    #As an example, assume that shift is 160 fs. Remainder in this case is 10 fs, so the data is shifed by -150 fs.
    #Now assume the shift is 170 fs. Remainder is 20 fs, but shifting by -150 fs is worse than shifting by -175 fs.
    #To account for that, the threshold for such decisions is 12.5 fs
    if fit_res[str(k)].values['x0'] < 0: #this is to take into account the sign of time-zero according to fit
        sign = -1 #if sign is negative
    else:
        sign = 1 #if sign is positive
    if abs(fit_res[str(k)].values['x0']%25) < 12.5: #checking if the remainder is more or less than 12.5 fs and shifting accoringly
        New_Delays[str(k)] = data[str(k)].Delays_on - ( fit_res[str(k)].values['x0'] - (sign*(abs(fit_res[str(k)].values['x0'])%25)) )
    else:
        New_Delays[str(k)] = data[str(k)].Delays_on - ( fit_res[str(k)].values['x0'] - (sign*(abs(fit_res[str(k)].values['x0'])%25)) + 25 ) #note extra +25 fs
    
    plt.figure(12) #plot the data corrected for exponent amplitude and time-zero
    plt.plot(New_Delays[str(k)], (data[str(k)].TFY_on - baseline) / amplitude )
    plt.xlim([-600,5000])
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (fs)')
    
# plt.figure(10,figsize=[16,8], dpi=200)
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()    
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_amplitude-corrected-only.png',dpi=300) #saving figures in .png file
# plt.figure(11,figsize=[16,8], dpi=200)  
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()  
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_fitted-curves.png',dpi=300) #saving figures in .png file
# plt.figure(12,figsize=[16,8], dpi=200)
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()    
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_amplitude-and-time-zero-corrected.png',dpi=300) #saving figures in .png file

Delays_temp = []
TFY_temp = []
TFY_std_temp = []
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # amplitude = fit_res[str(k)].values['amp_exp']
    amplitude = fit_res[str(k)].values['amp_exp1'] + fit_res[str(k)].values['amp_exp2']
    
    Delays_temp.extend( list(New_Delays[str(k)]) )
    TFY_temp.extend( list((data[str(k)].TFY_on - baseline) / amplitude) )
    TFY_std_temp.extend( (data[str(k)].TFY_on_std / amplitude) )
    
TFY_sorted_by_Delay = defaultdict(list)
for key,value in zip(Delays_temp,TFY_temp):
    try:
        TFY_sorted_by_Delay[key].append(value)
    except KeyError:    
        print('ERRRRRORRRRR')
        
TFY_std_sorted_by_Delay = defaultdict(list)
for key,value in zip(Delays_temp,TFY_std_temp):
    try:
        TFY_std_sorted_by_Delay[key].append(value)
    except KeyError:    
        print('ERRRRRORRRRR')

Delays_fin = []
TFY_fin = []
TFY_std_fin = []
for key in TFY_sorted_by_Delay:
    if np.isnan(key)==False:
        Delays_fin.append(key)        
        TFY_fin.append(np.nanmean(TFY_sorted_by_Delay[key]))
for key in TFY_std_sorted_by_Delay:
    if np.isnan(key)==False:
        TFY_std_fin.append(np.sqrt( sum(np.array(TFY_std_sorted_by_Delay[key])**2) / len(np.array(TFY_std_sorted_by_Delay[key])) ))

TFY_fin = [x for _, x in sorted(zip(Delays_fin, TFY_fin))]
TFY_std_fin = [x for _, x in sorted(zip(Delays_fin, TFY_std_fin))]
Delays_fin = [x for _, x in sorted(zip(Delays_fin, Delays_fin))]

# plt.figure(13)
# plt.errorbar(Delays_fin,TFY_fin,yerr=TFY_std_fin)

Delays_fin = np.array(Delays_fin)
TFY_fin = np.array(TFY_fin)
TFY_std_fin = np.array(TFY_std_fin)

# =============================================================================
# params_fin = lf.create_params( x0=dict(value=20, vary=True, min=-100, max=100), #Time zero in fs
#                       y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                       amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                       width=dict(value=270, vary=True, min=100, max=500), #Gaussian width
#                       amp_exp=dict(value=1, vary=True, min=0.8, max=1.2), #Exponent amplitude in a.u.
#                       tau=dict(value=13583, vary=True, min=10000, max=90000) ) #Exponent lifetime in fs
# =============================================================================

params_fin = lf.create_params( x0=dict(value=0, vary=True, min=-100, max=100), #Time zero in fs
                      y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
                      amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
                      width=dict(value=300, vary=True, min=100, max=500), #Gaussian width
                      amp_exp1=dict(value=0.5, vary=True, min=0.1, max=1), #Exponent amplitude in a.u.
                      tau1=dict(value=19486, vary=True, min=10000, max=50000), #Exponent lifetime in fs
                      amp_exp2=dict(value=0.5, vary=True, min=0.1, max=1), #Exponent amplitude in a.u.
                      tau2=dict(value=200000, vary=True, min=10000) ) #Exponent lifetime in fs
   
y_axis = np.array(TFY_fin[(Delays_fin<fit_range_u)])
x_axis = np.array(Delays_fin[(Delays_fin<fit_range_u)])
stddev = np.array(TFY_std_fin[(Delays_fin<fit_range_u)])

result_fin = gmodel.fit(y_axis, params_fin, x=x_axis,
                    weights = 1/stddev,
                    method = 'nelder')
fit_res_fin = result_fin
fit_report_fin = result_fin.fit_report()
# lf.model.save_modelresult(fit_res_fin, Save_Directory + EnergyXray + EnergyLaser + PolarisationLaser +'_averaged_fitted.sav')

# =============================================================================
# plt.figure(14,figsize=[16,8], dpi=200)
# plt.plot(x_axis, y_axis, '.', label='data')
# plt.plot(x_axis, fit_res_fin.init_fit, '--', label='initial fit')
# plt.plot(x_axis, fit_res_fin.best_fit, '-', label='best fit')
# plt.legend(loc='lower right')
# plt.xlim([min(x_axis)-max(x_axis), max(x_axis)])
# plt.ylabel('Intensity (a.u.)')
# plt.xlabel('Delay (fs)')
# plt.text(min(x_axis)-max(x_axis), min(y_axis), s=result_fin.fit_report(), fontsize=7)
# =============================================================================

figs, axes = plt.subplots(2,1, sharex=True, height_ratios=[5,1], num=14, figsize=[16,8], dpi=200)
figs.subplots_adjust(hspace=0)
axes[0].plot(x_axis, y_axis, '.', label='data')
axes[0].plot(x_axis, fit_res_fin.init_fit, '--', label='initial fit')
axes[0].plot(x_axis, fit_res_fin.best_fit, '-', label='best fit')
axes[0].legend(loc='upper right')
axes[0].set_ylabel('Intensity (a.u.)')
axes[0].text(min(x_axis)-max(x_axis), min(y_axis), s=result_fin.fit_report(), fontsize=7)
axes[1].plot(x_axis, fit_res_fin.residual)
# axes[1].set_ylabel('Resid')
axes[1].set_xlim([min(x_axis)-max(x_axis), max(x_axis)])
axes[1].set_xlabel('Delay (fs)')
    
mng = plt.get_current_fig_manager()
mng.window.showMaximized()
# plt.savefig(Save_Directory + EnergyXray + EnergyLaser + PolarisationLaser +'_averaged_fitted.png',dpi=300)
print(fit_res_fin.values)
# '''

print("--- %s seconds ---" % (time.time() - start_time))
   
#%% testing Heviside function
'''
def custom_hevi(x,x0,b):
    return b*np.heaviside(x-x0,1)

x = np.linspace(-15, 15, 1000)
data = custom_hevi(x,1,3) + np.random.normal(0, 0.1, x.size)

popt, pcov = curve_fit(custom_hevi, x, data, p0=[5, 5])
plt.figure(1)
plt.plot(x, custom_hevi(x, *popt))
plt.plot(x,data)
par = np.sqrt(np.diag(pcov))
residual = custom_hevi(x, *popt) - data

gmodel = lf.Model(custom_hevi)
params = lf.create_params( x0=dict(value=5, vary=True, min=-1, max=5, brute_step=0.2), 
                      b=dict(value=5, vary=True, min=-1, max=5, brute_step=0.2) )
result = gmodel.fit(data, params, x=x, method='brute')

print(result.fit_report())
plt.figure(2)
plt.plot(x, data, 'o')
plt.plot(x, result.init_fit, '--', label='initial fit')
plt.plot(x, result.best_fit, '-', label='best fit')
plt.legend()
'''

#%% Fitting boundaries
'''
x0l = -200; x0u = 500 #Time zero, set as a shift of a Heaviside function
y0l= 0; y0u = 0.055 #Background level
al = 0.2; au = 1.2 #Amplitude of a Gaussian
gl = 250; gu = 350 #FWHM of a Gaussian, should be same as rise time
bl = 0.03; bu = 0.2 #Amplitude of an exponent
taul = 20000; tauu = 35000 #Lifetime of an exponent
fit_range_u = 5000

fit_param = {}
fit_param2 = {}
fit_param3 = {}
chisq = {}
for k in Runs:
    # popt, pcov = curve_fit(custom_conv, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
    #                         p0=[100, 0.05, 0.9, 300, 0.136, 33000],
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]),
    #                         absolute_sigma=True,
    #                         sigma=data[str(k)].TFY_on_std[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]/np.sqrt(data[str(k)].N_values_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]) )
    popt, pcov, ac,acd,acdc = curve_fit(custom_conv, 
                            data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
                            data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
                            p0=[0.1, 20, 300, 20000],
                            bounds=([bl,x0l,gl,taul],[bu,x0u,gu,tauu]),
                            absolute_sigma=True, full_output=True,
                            sigma=data[str(k)].TFY_on_std[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]/np.sqrt(data[str(k)].N_values_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]) )
    # popt, pcov = curve_fit(errorfunction, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]))  
    # popt, pcov = curve_fit(expgauss, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]))
    # popt, pcov = curve_fit(errorfunction, 
    #                        data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<500)] , 
    #                        data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<500)])
    fit_param[str(k)] = popt
    fit_param2[str(k)] = pcov
    fit_param3[str(k)] = np.sqrt(np.diag(pcov))
    chisq[str(k)] = sum(( (data[str(k)].TFY_on - custom_conv(data[str(k)].Delays_on, *fit_param[str(k)])) / data[str(k)].TFY_on_std )**2) / np.size(data[str(k)].Delays_on)
perr = np.sqrt(np.diag(pcov))
for k in Runs:
    plt.figure(k)
    # plt.plot(data[str(k)].Delays_on, data[str(k)].TFY_on - data[str(k)].TFY_off)
    plt.errorbar(data[str(k)].Delays_on, data[str(k)].TFY_on - data[str(k)].TFY_off, yerr=data[str(k)].TFY_on_std/np.sqrt(data[str(k)].N_values_on))
    plt.plot(data[str(k)].Delays_on, custom_conv(data[str(k)].Delays_on, *fit_param[str(k)]))
    plt.xlim([-600,10000])
    
New_Delays = {}
plt.figure(2)
for k in Runs:
    New_Delays[str(k)] = data[str(k)].Delays_on - fit_param[str(k)][1]
    plt.plot(New_Delays[str(k)] , (data[str(k)].TFY_on-data[str(k)].TFY_off)/fit_param[str(k)][0])
    plt.xlim([-600,10000])
'''
