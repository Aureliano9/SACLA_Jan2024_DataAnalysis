# -*- coding: utf-8 -*-
"""
Created on Tue Aug 23 16:06:00 2022

@author: nurekeyev

Fitting XAS Kinetics data from SACLA
csv files are generated by sorting code
lmfit package is used
"""

import time
start_time = time.time()
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import lmfit as lf
from scipy import special
from scipy.integrate import quad,quad_vec
from collections import defaultdict


#define functions for fitting
def custom_errfunc(x,x0,y0,a,g):
    return y0 + a*(1+ special.erf((x-x0) / (g/np.sqrt(2)) ) )

#exponent multiplied by Heviside function. While x0 in the exponent is unnecessary,
#it is easier to interpret fit results when it's there
def custom_exp_hevi(x,amp_exp,tau,x0):
    return amp_exp*np.exp(-(x-x0)/tau)*np.heaviside(x-x0,0.5)

#Sum of two exponents multiplied by Heviside function.
def custom_double_exp_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0):
    return ( (amp_exp1*np.exp(-(x)/tau1)) + (amp_exp2*np.exp(-(x)/tau2)) ) * np.heaviside(x-x0,1)

#Gaussian. Coefficient 2.3548200450309493 makues sure that width is equal to FWHM of a Gaussian,
#hence, to an FWHM of a derivative of a rise-time of a fitted function custom_conv()
def custom_gauss(x,amp_gauss,width):
    return amp_gauss * ( 1/( (width/2.3548200450309493)*np.sqrt(2*np.pi)) ) * np.exp( -((x)**2) / (2*((width/2.3548200450309493)**2) ) )


#Convolution of functions custom_exp_hevi() and custom_gauss(). Convolution is not evaluated over the whole time range.
#Expected rise time is about 300 fs, 
#so a Gaussian of such a width is almost fully defind within 10*width, i.e. within 3000 fs 
#(that's what k-1500,k+1500 refers to, k is the center of a Gaussion).
#Evaluating the convolution over the whole time range doesn't improve the result.
#Also,since bin size in data is 25 fs, the grid is 5 fs, that's where 601 comes from.

def custom_conv(x,x0,y0,amp_gauss,width,amp_exp,tau):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1500, xk+1500, 601) #set the grid over which to integrate
        f1 = custom_exp_hevi(grid_x,amp_exp,tau,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Convolution of functions custom_double_exp_hevi() and custom_gauss()
def custom_conv2(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
    res_f = [] #final convoluted function 
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1500, xk+1500, 601) #set the grid over which to integrate
        f1 = custom_double_exp_hevi(grid_x,amp_exp1,tau1,amp_exp2,tau2,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

# =============================================================================
# def dd(x,x0,y0,amp_gauss,width,xc,amp_exp1,tau1,amp_exp2,tau2):
#     return custom_double_exp_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0)*custom_gauss(x,amp_gauss,width,xc)
# 
# def custom_conv2(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
#     res_f = [] #final convoluted function 
#     for xk in x: #
#         integral, err = quad(dd, xk-1500, xk+1500, args=(x0,y0,amp_gauss,width,xk,amp_exp1,tau1,amp_exp2,tau2)) #evaluating the integral
#         res_f.extend([integral]) 
#     return ( y0 + np.array(res_f) )
# =============================================================================

    
#Data directory and directory where to save the results
Directory ='C:/Users/nurekeye/Desktop/Projects/SACLA_05-2022/DataAnalysis/2023_06_21/'
Save_Directory = 'C:/Users/nurekeye/Desktop/Projects/SACLA_05-2022/DataAnalysis/Fit_results/2023_07_12/'

Runs0 = np.array([1145442]) #test runs

# Create empty dictionaries to fill them with Pandas DataFrames, each key corresponds to a run
data = {} #timing tool corrected
datau = {} #uncorrected

#load the data. Error appears if you have either Runs0 or Runs1 uncommented, but not both of them. That's intednded, ignore
if 'Runs0' in locals():
    Runs = Runs0
    for i in Runs0:
        # i=1145436
        data[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_0.csv', delimiter=',').replace(' ',np.nan).astype(float)
        # datau[str(i)] = pd.read_csv(Directory+str(i)+'_25fs_0_uncorrected.csv', delimiter=',').replace(' ',np.nan).astype(float)

#Set the model with lmfit
#Create empty dictionaries to fill with fit results
fit_res = {}
fit_report = {}
fit_range_u=5000 #Upper limit of fitting range in fs, lower limit hasn't been used so far

#Fitting itself. Standard deviation is used as weights.
#Common Levenbergâ€“Marquardt algorithm didn't work well, and among 20 different algorithms
#"differential evolution" method was the one with the best results, also it didn't take forever
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # y_axis = np.array(data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)])
    y_axis = np.array(data[str(k)].TFY_on[(data[str(k)].Delays_on<fit_range_u)] - baseline)
    x_axis = np.array(data[str(k)].Delays_on[(data[str(k)].Delays_on<fit_range_u)])
    stddev = np.array(data[str(k)].TFY_on_std[(data[str(k)].Delays_on<fit_range_u)])
    
    mid_value = np.mean( y_axis[(300<x_axis) & (x_axis<700)] )/2
    list_a = y_axis[x_axis<500]
    mid_value_real = list_a[min(range(len(list_a)), key=lambda i: abs(list_a[i]-mid_value))]
    t0 = x_axis[y_axis == mid_value_real]
    t0 = float(t0)
    amp_exp0 = float(abs(mid_value*2))
    
    gmodel = lf.Model(custom_conv)
    params = lf.create_params( x0=dict(value=t0, vary=True, min=-200, max=500), #Time zero in fs
                          y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
                          amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
                          width=dict(value=300, vary=True, min=100, max=500), #Gaussian width
                          amp_exp=dict(value=amp_exp0, vary=True, min=0.01, max=0.2), #Exponent amplitude in a.u.
                          tau=dict(value=19486, vary=True, min=10000, max=90000) ) #Exponent lifetime in fs
    
# =============================================================================
#     gmodel = lf.Model(custom_conv2)
#     params = lf.create_params( x0=dict(value=t0+20, vary=True, min=-200, max=500), #Time zero in fs
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=300, vary=True, min=100, max=500), #Gaussian width
#                           amp_exp1=dict(value=amp_exp0/2, vary=True, min=0.001, max=0.2), #Exponent amplitude in a.u.
#                           tau1=dict(value=19486, vary=True, min=10000, max=50000), #Exponent lifetime in fs
#                           amp_exp2=dict(value=amp_exp0/2, vary=True, min=0.001, max=0.2), #Exponent amplitude in a.u.
#                           tau2=dict(value=200000, vary=True, min=10000) ) #Exponent lifetime in fs
# =============================================================================
    
# =============================================================================
#     gmodel = lf.Model(custom_errfunc)
#     params = lf.create_params( x0=dict(value=100, vary=True, min=-200, max=500), #Time zero in fs
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           a=dict(value=0.0386, vary=True, min=0.01, max=0.2), #Error function amplitude in a.u.
#                           g=dict(value=237, vary=True, min=100, max=500)) #Error function width in ps
# =============================================================================
        
    result = gmodel.fit(y_axis, params=params, x=x_axis, 
                        weights = 1/stddev,
                        method = 'nelder')
    fit_res[str(k)] = result #save fit results in internal lmfit format
    fit_report[str(k)] = result.fit_report() #save fit report
    # lf.model.save_modelresult(fit_res[str(k)], Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/'+str(k) + EnergyLaser + '.sav') #saving fit results in internal lmfit format in .sav file for 2.9 uJ

# =============================================================================
#     #Plotting the fit results.    
#     plt.figure(str(k),figsize=[16,8], dpi=200)
#     plt.plot(x_axis, y_axis, '.', label='data')
#     plt.plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
#     plt.plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
#     plt.legend(loc='upper right')
#     plt.xlim([min(x_axis)-max(x_axis), max(x_axis)])
#     plt.ylabel('Intensity (a.u.)')
#     plt.xlabel('Delay (fs)')
#     plt.text(min(x_axis)-max(x_axis), min(y_axis), s=result.fit_report(), fontsize=7)
# =============================================================================
    
    figs, axes = plt.subplots(2,1, sharex=True, height_ratios=[5,1], num=k, figsize=[16,8], dpi=200)
    figs.subplots_adjust(hspace=0)
    axes[0].plot(x_axis, y_axis, '.', label='data')
    axes[0].plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
    axes[0].plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
    axes[0].legend(loc='upper right')
    axes[0].set_ylabel('Intensity (a.u.)')
    axes[0].text(min(x_axis)-max(x_axis), min(y_axis), s=fit_res[str(k)].fit_report(), fontsize=7)
    axes[1].plot(x_axis, fit_res[str(k)].residual)
    # axes[1].set_ylabel('Resid')
    axes[1].set_xlim([min(x_axis)-max(x_axis), max(x_axis)])
    axes[1].set_xlabel('Delay (fs)')

    mng = plt.get_current_fig_manager()
    mng.window.showMaximized()
    # plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/'+str(k)+ EnergyLaser + '.png',dpi=300) #saving figures in .png file for 2.9 uJ
    print(fit_res[str(k)].values)

    fig, axes = plt.subplots(1,1, num=k*2, dpi=200)
    comps = fit_res[str(k)].eval_components(x=x_axis)
    dely = fit_res[str(k)].eval_uncertainty(sigma=3)
    axes.plot(x_axis, y_axis, '.', markersize=3, label='data')
    axes.plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
    axes.fill_between(x_axis, fit_res[str(k)].best_fit-dely, fit_res[str(k)].best_fit+dely,
                            color="#C5C9C7", label=r'3-$\sigma$ band')
    axes.set_title('data, best-fit, and uncertainty band')
    axes.legend()
